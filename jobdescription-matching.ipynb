{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\njd = pd.read_csv('../input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv')\nresume = pd.read_csv('../input/resume-dataset/UpdatedResumeDataSet.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:32:59.898096Z","iopub.execute_input":"2021-12-24T15:32:59.898695Z","iopub.status.idle":"2021-12-24T15:33:01.048407Z","shell.execute_reply.started":"2021-12-24T15:32:59.898595Z","shell.execute_reply":"2021-12-24T15:33:01.047455Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras import Model\nimport numpy as np\nimport pandas as pd\nimport transformers","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:01.050604Z","iopub.execute_input":"2021-12-24T15:33:01.051039Z","iopub.status.idle":"2021-12-24T15:33:06.911616Z","shell.execute_reply.started":"2021-12-24T15:33:01.051001Z","shell.execute_reply":"2021-12-24T15:33:06.910880Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"com = []\nfor c in resume['Category'].unique():\n    if(c in jd['title'].unique()):\n        com.append(c)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:06.913269Z","iopub.execute_input":"2021-12-24T15:33:06.913508Z","iopub.status.idle":"2021-12-24T15:33:06.996661Z","shell.execute_reply.started":"2021-12-24T15:33:06.913476Z","shell.execute_reply":"2021-12-24T15:33:06.995915Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"jd1 = jd[jd['title'].isin(com)]\njd1 = jd1[['title','description']]\nresume1 = resume[resume['Category'].isin(com)]\nresume1 = resume1.rename(columns={'Category': 'title'})","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:06.997892Z","iopub.execute_input":"2021-12-24T15:33:06.998218Z","iopub.status.idle":"2021-12-24T15:33:07.010392Z","shell.execute_reply.started":"2021-12-24T15:33:06.998184Z","shell.execute_reply":"2021-12-24T15:33:07.009600Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(f'resume shape : {resume1.shape} jd shape : {jd1.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:07.012154Z","iopub.execute_input":"2021-12-24T15:33:07.012756Z","iopub.status.idle":"2021-12-24T15:33:07.021256Z","shell.execute_reply.started":"2021-12-24T15:33:07.012722Z","shell.execute_reply":"2021-12-24T15:33:07.020271Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for i in range(len(resume1)):\n    s = resume1.iloc[i,1]\n    s = ' '.join(w for w in s.split() if w.isalnum())\n    s = s.strip()\n    resume1.iloc[i,1] = s","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:07.022821Z","iopub.execute_input":"2021-12-24T15:33:07.023190Z","iopub.status.idle":"2021-12-24T15:33:07.165238Z","shell.execute_reply.started":"2021-12-24T15:33:07.023151Z","shell.execute_reply":"2021-12-24T15:33:07.164550Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"resume1 = resume1[resume1['Resume'].str.split().str.len().lt(1000)]","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:07.166368Z","iopub.execute_input":"2021-12-24T15:33:07.168334Z","iopub.status.idle":"2021-12-24T15:33:07.193801Z","shell.execute_reply.started":"2021-12-24T15:33:07.168304Z","shell.execute_reply":"2021-12-24T15:33:07.193001Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for i in range(len(jd1)):\n    s = jd1.iloc[i,1]\n    s = ' '.join(w for w in s.split() if w.isalnum())\n    s = s.strip()\n    jd1.iloc[i,1] = s","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:07.194869Z","iopub.execute_input":"2021-12-24T15:33:07.195542Z","iopub.status.idle":"2021-12-24T15:33:07.233827Z","shell.execute_reply.started":"2021-12-24T15:33:07.195502Z","shell.execute_reply":"2021-12-24T15:33:07.233046Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"resume1.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:07.235354Z","iopub.execute_input":"2021-12-24T15:33:07.235621Z","iopub.status.idle":"2021-12-24T15:33:07.252964Z","shell.execute_reply.started":"2021-12-24T15:33:07.235585Z","shell.execute_reply":"2021-12-24T15:33:07.252299Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"jd1.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:07.254188Z","iopub.execute_input":"2021-12-24T15:33:07.254446Z","iopub.status.idle":"2021-12-24T15:33:07.263354Z","shell.execute_reply.started":"2021-12-24T15:33:07.254414Z","shell.execute_reply":"2021-12-24T15:33:07.262426Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"max_resume_len = max([len(s.split()) for s in resume1['Resume']])\nprint(max_resume_len)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:08.443530Z","iopub.execute_input":"2021-12-24T15:33:08.443780Z","iopub.status.idle":"2021-12-24T15:33:08.455835Z","shell.execute_reply.started":"2021-12-24T15:33:08.443752Z","shell.execute_reply":"2021-12-24T15:33:08.454913Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nl = [len(s.split()) for s in resume1['Resume']]\nplt.hist(l)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:08.737980Z","iopub.execute_input":"2021-12-24T15:33:08.738225Z","iopub.status.idle":"2021-12-24T15:33:08.979774Z","shell.execute_reply.started":"2021-12-24T15:33:08.738197Z","shell.execute_reply":"2021-12-24T15:33:08.979074Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"max_jd_len = max([len(s.split()) for s in jd1['description']])\nprint(max_jd_len)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:09.021540Z","iopub.execute_input":"2021-12-24T15:33:09.021733Z","iopub.status.idle":"2021-12-24T15:33:09.028283Z","shell.execute_reply.started":"2021-12-24T15:33:09.021710Z","shell.execute_reply":"2021-12-24T15:33:09.027389Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"jd_count = jd1.groupby('title').count()\nresume_count = resume1.groupby('title').count()\njd_count['Resume'] = resume_count['Resume']\njd_count.plot.bar()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:09.247116Z","iopub.execute_input":"2021-12-24T15:33:09.247612Z","iopub.status.idle":"2021-12-24T15:33:09.529834Z","shell.execute_reply.started":"2021-12-24T15:33:09.247576Z","shell.execute_reply":"2021-12-24T15:33:09.529082Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"len(resume1)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:10.422496Z","iopub.execute_input":"2021-12-24T15:33:10.422811Z","iopub.status.idle":"2021-12-24T15:33:10.429180Z","shell.execute_reply.started":"2021-12-24T15:33:10.422777Z","shell.execute_reply":"2021-12-24T15:33:10.428289Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(jd1)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:10.602552Z","iopub.execute_input":"2021-12-24T15:33:10.602784Z","iopub.status.idle":"2021-12-24T15:33:10.607693Z","shell.execute_reply.started":"2021-12-24T15:33:10.602757Z","shell.execute_reply":"2021-12-24T15:33:10.606980Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data = []\nfor i in range(len(jd1)):\n    for j in range(len(resume1)):\n        l = []\n        l.append(jd1.iloc[i,1])\n        l.append(resume1.iloc[j,1])\n        if jd1.iloc[i,0]==resume1.iloc[j,0]:\n            l.append(0)\n        else:\n            l.append(1)\n        data.append(l)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:10.782524Z","iopub.execute_input":"2021-12-24T15:33:10.782768Z","iopub.status.idle":"2021-12-24T15:33:16.151598Z","shell.execute_reply.started":"2021-12-24T15:33:10.782741Z","shell.execute_reply":"2021-12-24T15:33:16.150823Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data1 = pd.DataFrame(data, columns = ['description', 'resume', 'similarity'])","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:16.153007Z","iopub.execute_input":"2021-12-24T15:33:16.153232Z","iopub.status.idle":"2021-12-24T15:33:16.177635Z","shell.execute_reply.started":"2021-12-24T15:33:16.153201Z","shell.execute_reply":"2021-12-24T15:33:16.176679Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df = data1.sample(frac=1).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:16.179017Z","iopub.execute_input":"2021-12-24T15:33:16.179424Z","iopub.status.idle":"2021-12-24T15:33:16.194852Z","shell.execute_reply.started":"2021-12-24T15:33:16.179390Z","shell.execute_reply":"2021-12-24T15:33:16.194094Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"y = tf.keras.utils.to_categorical(df.similarity, num_classes=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:16.197843Z","iopub.execute_input":"2021-12-24T15:33:16.199404Z","iopub.status.idle":"2021-12-24T15:33:16.203924Z","shell.execute_reply.started":"2021-12-24T15:33:16.199367Z","shell.execute_reply":"2021-12-24T15:33:16.203297Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, valid_df,y_train, y_val = train_test_split(df,y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:16.205265Z","iopub.execute_input":"2021-12-24T15:33:16.206035Z","iopub.status.idle":"2021-12-24T15:33:16.783144Z","shell.execute_reply.started":"2021-12-24T15:33:16.205999Z","shell.execute_reply":"2021-12-24T15:33:16.782425Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_df.groupby('similarity').count()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:16.784540Z","iopub.execute_input":"2021-12-24T15:33:16.784798Z","iopub.status.idle":"2021-12-24T15:33:16.803819Z","shell.execute_reply.started":"2021-12-24T15:33:16.784764Z","shell.execute_reply":"2021-12-24T15:33:16.803154Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"max_length = 512  # Maximum length of input sentence to the model.\nbatch_size = 32\nepochs = 2","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:16.804870Z","iopub.execute_input":"2021-12-24T15:33:16.805131Z","iopub.status.idle":"2021-12-24T15:33:16.809348Z","shell.execute_reply.started":"2021-12-24T15:33:16.805089Z","shell.execute_reply":"2021-12-24T15:33:16.808504Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n    \"\"\"Generates batches of data.\n\n    Args:\n        sentence_pairs: Array of premise and hypothesis input sentences.\n        labels: Array of labels.\n        batch_size: Integer batch size.\n        shuffle: boolean, whether to shuffle the data.\n        include_targets: boolean, whether to incude the labels.\n\n    Returns:\n        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n        (or just `[input_ids, attention_mask, `token_type_ids]`\n         if `include_targets=False`)\n    \"\"\"\n\n    def __init__(\n        self,\n        sentence_pairs,\n        labels,\n        batch_size=batch_size,\n        shuffle=True,\n        include_targets=True,\n    ):\n        self.sentence_pairs = sentence_pairs\n        self.labels = labels\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.include_targets = include_targets\n        # Load our BERT Tokenizer to encode the text.\n        # We will use base-base-uncased pretrained model.\n        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n            \"bert-base-uncased\", do_lower_case=True\n        )\n        self.indexes = np.arange(len(self.sentence_pairs))\n        self.on_epoch_end()\n\n    def __len__(self):\n        # Denotes the number of batches per epoch.\n        return len(self.sentence_pairs) // self.batch_size\n\n    def __getitem__(self, idx):\n        # Retrieves the batch of index.\n        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n        sentence_pairs = self.sentence_pairs[indexes]\n\n        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n        # encoded together and separated by [SEP] token.\n        encoded = self.tokenizer.batch_encode_plus(\n            sentence_pairs.tolist(),\n            add_special_tokens=True,\n            max_length=max_length,\n            return_attention_mask=True,\n            return_token_type_ids=True,\n            pad_to_max_length=True,\n            return_tensors=\"tf\",\n        )\n\n        # Convert batch of encoded features to numpy array.\n        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n\n        # Set to true if data generator is used for training/validation.\n        if self.include_targets:\n            labels = np.array(self.labels[indexes], dtype=\"int32\")\n            return [input_ids, attention_masks, token_type_ids], labels\n        else:\n            return [input_ids, attention_masks, token_type_ids]\n\n    def on_epoch_end(self):\n        # Shuffle indexes after each epoch if shuffle is set to True.\n        if self.shuffle:\n            np.random.RandomState(42).shuffle(self.indexes)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:16.810728Z","iopub.execute_input":"2021-12-24T15:33:16.811108Z","iopub.status.idle":"2021-12-24T15:33:16.825412Z","shell.execute_reply.started":"2021-12-24T15:33:16.811070Z","shell.execute_reply":"2021-12-24T15:33:16.824738Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope():\n    # Encoded token ids from BERT tokenizer.\n    input_ids = tf.keras.layers.Input(\n        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n    )\n    # Attention masks indicates to the model which tokens should be attended to.\n    attention_masks = tf.keras.layers.Input(\n        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n    )\n    # Token type ids are binary masks identifying different sequences in the model.\n    token_type_ids = tf.keras.layers.Input(\n        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n    )\n    # Loading pretrained BERT model.\n    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n    # Freeze the BERT model to reuse the pretrained features without modifying them.\n    bert_model.trainable = False\n\n    bert_output = bert_model(\n        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n    )\n    sequence_output = bert_output.last_hidden_state\n    pooled_output = bert_output.pooler_output\n    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n    bi_lstm = tf.keras.layers.Bidirectional(\n        tf.keras.layers.LSTM(64, return_sequences=True)\n    )(sequence_output)\n    # Applying hybrid pooling approach to bi_lstm sequence output.\n    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n    dropout = tf.keras.layers.Dropout(0.3)(concat)\n    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n    model = tf.keras.models.Model(\n        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n    )\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"acc\"],\n    )\n\n\nprint(f\"Strategy: {strategy}\")\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:33:16.826797Z","iopub.execute_input":"2021-12-24T15:33:16.827545Z","iopub.status.idle":"2021-12-24T15:33:56.478553Z","shell.execute_reply.started":"2021-12-24T15:33:16.827508Z","shell.execute_reply":"2021-12-24T15:33:56.477893Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_data = BertSemanticDataGenerator(\n    train_df[[\"description\", \"resume\"]].values.astype(\"str\"),\n    y_train,\n    batch_size=batch_size,\n    shuffle=True,\n)\nvalid_data = BertSemanticDataGenerator(\n    valid_df[[\"description\", \"resume\"]].values.astype(\"str\"),\n    y_val,\n    batch_size=batch_size,\n    shuffle=False,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:34:22.068863Z","iopub.execute_input":"2021-12-24T15:34:22.069127Z","iopub.status.idle":"2021-12-24T15:34:29.852770Z","shell.execute_reply.started":"2021-12-24T15:34:22.069086Z","shell.execute_reply":"2021-12-24T15:34:29.851964Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    validation_data=valid_data,\n    epochs=epochs,\n    use_multiprocessing=True,\n    workers=-1,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T15:34:29.854297Z","iopub.execute_input":"2021-12-24T15:34:29.854535Z","iopub.status.idle":"2021-12-24T16:13:23.873448Z","shell.execute_reply.started":"2021-12-24T15:34:29.854500Z","shell.execute_reply":"2021-12-24T16:13:23.872752Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T16:13:55.751574Z","iopub.execute_input":"2021-12-24T16:13:55.751851Z","iopub.status.idle":"2021-12-24T16:13:55.980944Z","shell.execute_reply.started":"2021-12-24T16:13:55.751820Z","shell.execute_reply":"2021-12-24T16:13:55.980211Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"bert_model.trainable = True\n# Recompile the model to make the change effective.\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-5),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T16:20:54.251079Z","iopub.execute_input":"2021-12-24T16:20:54.251965Z","iopub.status.idle":"2021-12-24T16:20:54.303646Z","shell.execute_reply.started":"2021-12-24T16:20:54.251911Z","shell.execute_reply":"2021-12-24T16:20:54.302909Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    validation_data=valid_data,\n    epochs=epochs,\n    use_multiprocessing=True,\n    workers=-1,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T16:20:56.034060Z","iopub.execute_input":"2021-12-24T16:20:56.034858Z","iopub.status.idle":"2021-12-24T16:21:25.882541Z","shell.execute_reply.started":"2021-12-24T16:20:56.034814Z","shell.execute_reply":"2021-12-24T16:21:25.880657Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def check_similarity(sentence1, sentence2):\n    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n    test_data = BertSemanticDataGenerator(\n        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n    )\n\n    proba = model.predict(test_data[0])[0]\n    return 1-max(proba)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T16:19:27.531282Z","iopub.execute_input":"2021-12-24T16:19:27.531927Z","iopub.status.idle":"2021-12-24T16:19:27.537486Z","shell.execute_reply.started":"2021-12-24T16:19:27.531885Z","shell.execute_reply":"2021-12-24T16:19:27.536605Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"sentence1 = df.iloc[0,0]\nsentence2 = df.iloc[0,1]\ncheck_similarity(sentence1, sentence2)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T16:19:27.949934Z","iopub.execute_input":"2021-12-24T16:19:27.950198Z","iopub.status.idle":"2021-12-24T16:19:30.660944Z","shell.execute_reply.started":"2021-12-24T16:19:27.950169Z","shell.execute_reply":"2021-12-24T16:19:30.660276Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}